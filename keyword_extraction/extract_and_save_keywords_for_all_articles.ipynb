{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "087a0ed9-574b-48b9-9307-ec3c3feb2ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranavgoel/miniconda3/envs/pg3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rake_nltk import Rake\n",
    "import pytz\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71a63c24-c042-4ad8-b570-5f7ab7a975a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newyork_article_texts_and_info_dedup.csv', 'nytimes_foxnews_article_texts_and_info_dedup.csv', 'florida_article_texts_and_info_dedup.csv', 'illinois_article_texts_and_info_dedup.csv', 'texas_article_texts_and_info_dedup.csv', 'california_article_texts_and_info_dedup.csv', 'ohio_article_texts_and_info_dedup.csv']\n"
     ]
    }
   ],
   "source": [
    "input_base_path = '../obtaining_news_collections/data/'\n",
    "input_file_names = [x for x in os.listdir(input_base_path) if 'dedup.csv' in x]\n",
    "print(input_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77ae92-7df8-49e1-9dc4-4b0f5390b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for text, using title + article text combined. \n",
    "#output will be indexed using url, and each state and (nytimes foxnews) will be done separately to create 7 files\n",
    "#each file is a dictionary, from url -> (timestamp, [(score, keyword/phrase), ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b51b033c-d25b-435d-8649-62c68118217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dated_keywords(ts_text_tuples, \n",
    "                       min_length=1, \n",
    "                       max_length=3):\n",
    "    \"\"\"\n",
    "    Given ts_text_tuples, a list of (timestamp, article_text) tuples,\n",
    "    extract & return a list of timestamped keywords + scores using rake-nltk. \n",
    "    \"\"\"\n",
    "    dated_keywords = []\n",
    "    r = Rake(min_length=min_length, max_length=max_length)\n",
    "    for tup in tqdm(ts_text_tuples):\n",
    "        r.extract_keywords_from_text(tup[1])\n",
    "        kw = r.get_ranked_phrases_with_scores()\n",
    "        dated_keywords.append((tup[0], kw))\n",
    "    \n",
    "    return dated_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69fa8bfe-1f36-4ed0-b88c-d1aab4e28132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newyork\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2910/2910 [00:08<00:00, 357.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nytimes_foxnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 944/944 [00:01<00:00, 538.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "florida\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1283/1283 [00:03<00:00, 408.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "illinois\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 692/692 [00:01<00:00, 383.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1816/1816 [00:04<00:00, 431.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "california\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7571/7571 [00:30<00:00, 244.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ohio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 667/667 [00:02<00:00, 322.44it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in input_file_names:#, position = 0, leave=False):\n",
    "    media_group = f.split('_article_')[0]\n",
    "    print(media_group)\n",
    "    df = pd.read_csv(input_base_path + f)\n",
    "    urls = list(df['url'])\n",
    "    dates = list(df['publish_date'])\n",
    "    titles_and_texts = list(zip(df['title'], df['text']))\n",
    "    titles_and_texts = list(map(lambda x:x[0] + '\\n\\n\\n' + x[1], titles_and_texts))\n",
    "    dated_keywords = get_dated_keywords(list(zip(dates, titles_and_texts)))\n",
    "    assert len(dated_keywords)==len(urls)\n",
    "    out = dict(zip(urls, dated_keywords))\n",
    "    pickle.dump(out,\n",
    "                open(media_group + '_url_to_dated_keywords.pkl',\n",
    "                          'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce9464-f27c-4b3b-8f9a-5b72c4938cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ab8382-d889-4388-996d-3d76f9cad7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
